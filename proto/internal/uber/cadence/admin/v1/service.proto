// Copyright (c) 2020 Uber Technologies, Inc.
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in
// all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
// THE SOFTWARE.

syntax = "proto3";

package uber.cadence.admin.v1;

option go_package = "github.com/uber/cadence/.gen/proto/admin/v1;adminv1";

import "google/protobuf/timestamp.proto";
import "google/protobuf/wrappers.proto";
import "uber/cadence/api/v1/common.proto";
import "uber/cadence/api/v1/visibility.proto";
import "uber/cadence/shared/v1/cluster.proto";
import "uber/cadence/shared/v1/history.proto";
import "uber/cadence/shared/v1/queue.proto";
import "uber/cadence/shared/v1/replication.proto";

// AdminAPI provides advanced APIs for debugging and analysis with admin privilege.
service AdminAPI {
  // DescribeWorkflowExecution returns information about the internal states of workflow execution.
  rpc DescribeWorkflowExecution(DescribeWorkflowExecutionRequest) returns (DescribeWorkflowExecutionResponse);

  // DescribeHistoryHost returns information about the internal states of a history host.
  rpc DescribeHistoryHost(DescribeHistoryHostRequest) returns (DescribeHistoryHostResponse);

  // CloseShard closes shard.
  rpc CloseShard(CloseShardRequest) returns (CloseShardResponse);

  // RemoveTask removes task.
  rpc RemoveTask(RemoveTaskRequest) returns (RemoveTaskResponse);

  // ResetQueue resets queue.
  rpc ResetQueue(ResetQueueRequest) returns (ResetQueueResponse);

  // DescribeQueue describes queue.
  rpc DescribeQueue(DescribeQueueRequest) returns(DescribeQueueResponse);

  // Returns the raw history of specified workflow execution.
  // It fails with 'EntityNotExistError' if specified workflow execution in unknown to the service.
  // StartEventId defines the beginning of the event to fetch. The first event is inclusive.
  // EndEventId and EndEventVersion defines the end of the event to fetch. The end event is exclusive.
  rpc GetWorkflowExecutionRawHistoryV2(GetWorkflowExecutionRawHistoryV2Request) returns(GetWorkflowExecutionRawHistoryV2Response);

  // GetReplicationMessages returns new replication tasks since the read level provided in the token.
  rpc GetReplicationMessages(GetReplicationMessagesRequest) returns(GetReplicationMessagesResponse);

  // GetDLQReplicationMessages return replication messages based on DLQ info.
  rpc GetDLQReplicationMessages(GetDLQReplicationMessagesRequest) returns (GetDLQReplicationMessagesResponse);

  // GetDomainReplicationMessages returns new domain replication tasks since last retrieved task id.
  rpc GetDomainReplicationMessages (GetDomainReplicationMessagesRequest) returns (GetDomainReplicationMessagesResponse);

  // ReapplyEvents applies stale events to the current workflow and current run.
  rpc ReapplyEvents(ReapplyEventsRequest) returns (ReapplyEventsResponse);

  // AddSearchAttribute whitelist search attribute in request.
  rpc AddSearchAttribute (AddSearchAttributeRequest) returns (AddSearchAttributeResponse);

  // DescribeCluster returns information about Cadence cluster.
  rpc DescribeCluster(DescribeClusterRequest) returns (DescribeClusterResponse);

  // ReadDLQMessages returns messages from DLQ.
  rpc ReadDLQMessages(ReadDLQMessagesRequest) returns (ReadDLQMessagesResponse);

  // PurgeDLQMessages purges messages from DLQ.
  rpc PurgeDLQMessages(PurgeDLQMessagesRequest) returns (PurgeDLQMessagesResponse);

  // MergeDLQMessages merges messages from DLQ.
  rpc MergeDLQMessages(MergeDLQMessagesRequest) returns (MergeDLQMessagesResponse);

  // RefreshWorkflowTasks refreshes all tasks of a workflow.
  rpc RefreshWorkflowTasks(RefreshWorkflowTasksRequest) returns (RefreshWorkflowTasksResponse);

  // ResendReplicationTasks requests replication tasks from remote cluster and apply tasks to current cluster.
  rpc ResendReplicationTasks(ResendReplicationTasksRequest) returns (ResendReplicationTasksResponse);
}

message DescribeWorkflowExecutionRequest {
  string domain = 1;
  api.v1.WorkflowExecution workflow_execution = 2;
}

message DescribeWorkflowExecutionResponse {
  int32 shard_id = 1;
  string history_addr = 2;
  string mutable_state_in_cache = 3;
  string mutable_state_in_database = 4;
}

message DescribeHistoryHostRequest {
  oneof describe_by {
    string host_address = 1;
    int32 shard_id = 2;
    api.v1.WorkflowExecution workflow_execution = 3;
  }
}

message DescribeHistoryHostResponse {
  int32 number_of_shards = 1;
  repeated int32 shard_ids = 2;
  shared.v1.DomainCacheInfo domain_cache = 3;
  string shard_controller_status = 4;
  string address = 5;
}

message CloseShardRequest {
  int32 shard_id = 1;
}

message CloseShardResponse {
}

message RemoveTaskRequest {
  int32 shard_id = 1;
  shared.v1.TaskType task_type = 2;
  int64 task_id = 3;
  google.protobuf.Timestamp visibility_time = 4;
}

message RemoveTaskResponse {
}

message ResetQueueRequest {
  int32 shard_id = 1;
  string cluster_name = 2;
  shared.v1.TaskType task_type = 3;
}

message ResetQueueResponse {
}

message DescribeQueueRequest {
  int32 shard_id = 1;
  string cluster_name = 2;
  shared.v1.TaskType task_type = 3;
}

message DescribeQueueResponse {
  repeated string processing_queue_states = 1;
}

message GetWorkflowExecutionRawHistoryV2Request {
  string domain = 1;
  api.v1.WorkflowExecution workflow_execution = 2;
  shared.v1.VersionHistoryItem start_event = 3;
  shared.v1.VersionHistoryItem end_event = 4;
  int32 page_size = 5;
  bytes next_page_token = 6;
}

message GetWorkflowExecutionRawHistoryV2Response {
  bytes next_page_token = 1;
  repeated api.v1.DataBlob history_batches = 2;
  shared.v1.VersionHistory version_history = 3;
}

message GetReplicationMessagesRequest {
  repeated shared.v1.ReplicationToken tokens = 1;
  string cluster_name = 2;
}

message GetReplicationMessagesResponse {
  map<int32, shared.v1.ReplicationMessages> shard_messages = 1;
}

message GetDLQReplicationMessagesRequest {
  repeated shared.v1.ReplicationTaskInfo task_infos = 1;
}

message GetDLQReplicationMessagesResponse {
  repeated shared.v1.ReplicationTask replication_tasks = 1;
}

message GetDomainReplicationMessagesRequest {
  // last_retrieved_message_id is where the next fetch should begin with.
  google.protobuf.Int64Value last_retrieved_message_id = 1;
  // last_processed_message_id is the last messageId that is processed on the passive side.
  // This can be different than last_retrieved_message_id if passive side supports prefetching messages.
  google.protobuf.Int64Value last_processed_message_id = 2;
  // cluster_name is the name of the pulling cluster.
  string cluster_name = 3;
}

message GetDomainReplicationMessagesResponse {
  shared.v1.ReplicationMessages messages = 1;
}

// ReapplyEventsRequest is the request for reapply events API.
message ReapplyEventsRequest {
  string domain = 1;
  api.v1.WorkflowExecution workflow_execution = 2;
  api.v1.DataBlob events = 3;
}

message ReapplyEventsResponse {
}

message AddSearchAttributeRequest {
  map<string, api.v1.IndexedValueType> search_attribute = 1;
  string security_token = 2;
}

message AddSearchAttributeResponse {
}

message DescribeClusterRequest {
}

message DescribeClusterResponse {
  api.v1.SupportedClientVersions supported_client_versions = 1;
  shared.v1.MembershipInfo membership_info = 2;
}

message ReadDLQMessagesRequest {
  shared.v1.DLQType type = 1;
  int32 shard_id = 2;
  string source_cluster = 3;
  google.protobuf.Int64Value inclusive_end_message_id = 4;
  int32 page_size = 5;
  bytes next_page_token = 6;
}

message ReadDLQMessagesResponse {
  shared.v1.DLQType type = 1;
  repeated shared.v1.ReplicationTask replication_tasks = 2;
  bytes next_page_token = 3;
}

message PurgeDLQMessagesRequest {
  shared.v1.DLQType type = 1;
  int32 shard_id = 2;
  string source_cluster = 3;
  google.protobuf.Int64Value inclusive_end_message_id = 4;
}

message PurgeDLQMessagesResponse {
}

message MergeDLQMessagesRequest {
  shared.v1.DLQType type = 1;
  int32 shard_id = 2;
  string source_cluster = 3;
  google.protobuf.Int64Value inclusive_end_message_id = 4;
  int32 page_size = 5;
  bytes next_page_token = 6;
}

message MergeDLQMessagesResponse {
  bytes next_page_token = 1;
}

message RefreshWorkflowTasksRequest {
  string domain = 1;
  api.v1.WorkflowExecution workflow_execution = 2;
}

message RefreshWorkflowTasksResponse {
}

message ResendReplicationTasksRequest {
  string domain_id = 1;
  api.v1.WorkflowExecution workflow_execution = 2;
  string remote_cluster = 3;
  shared.v1.VersionHistoryItem start_event = 4;
  shared.v1.VersionHistoryItem end_event = 5;
}

message ResendReplicationTasksResponse {
}
